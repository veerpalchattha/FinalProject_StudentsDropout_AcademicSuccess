{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f559a2c-57de-4ab5-9591-e20cbc39e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Student Outcomes ML Pipeline (Graduate / Dropout / Enrolled)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097b7f16-5255-4938-ac36-71c060464fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4424, 37)\n",
      "\n",
      "Target distribution:\n",
      " Target\n",
      "Graduate    2209\n",
      "Dropout     1421\n",
      "Enrolled     794\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 1) Load dataset\n",
    "# -----------------------\n",
    "DATA_PATH = \"../data/raw/data.csv\"\n",
    "df = pd.read_csv(DATA_PATH, sep=\";\")   # IMPORTANT: your file is ';' separated\n",
    "\n",
    "TARGET_COL = \"Target\"\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nTarget distribution:\\n\", y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8becc01d-797f-4339-8d40-522fc2fa7037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital status                                      int64\n",
       "Application mode                                    int64\n",
       "Application order                                   int64\n",
       "Course                                              int64\n",
       "Daytime/evening attendance\\t                        int64\n",
       "Previous qualification                              int64\n",
       "Previous qualification (grade)                    float64\n",
       "Nacionality                                         int64\n",
       "Mother's qualification                              int64\n",
       "Father's qualification                              int64\n",
       "Mother's occupation                                 int64\n",
       "Father's occupation                                 int64\n",
       "Admission grade                                   float64\n",
       "Displaced                                           int64\n",
       "Educational special needs                           int64\n",
       "Debtor                                              int64\n",
       "Tuition fees up to date                             int64\n",
       "Gender                                              int64\n",
       "Scholarship holder                                  int64\n",
       "Age at enrollment                                   int64\n",
       "International                                       int64\n",
       "Curricular units 1st sem (credited)                 int64\n",
       "Curricular units 1st sem (enrolled)                 int64\n",
       "Curricular units 1st sem (evaluations)              int64\n",
       "Curricular units 1st sem (approved)                 int64\n",
       "Curricular units 1st sem (grade)                  float64\n",
       "Curricular units 1st sem (without evaluations)      int64\n",
       "Curricular units 2nd sem (credited)                 int64\n",
       "Curricular units 2nd sem (enrolled)                 int64\n",
       "Curricular units 2nd sem (evaluations)              int64\n",
       "Curricular units 2nd sem (approved)                 int64\n",
       "Curricular units 2nd sem (grade)                  float64\n",
       "Curricular units 2nd sem (without evaluations)      int64\n",
       "Unemployment rate                                 float64\n",
       "Inflation rate                                    float64\n",
       "GDP                                               float64\n",
       "Target                                             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52871702-64b6-4f85-a9b9-5b211edf75b6",
   "metadata": {},
   "source": [
    "###### df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b530fe-5ce6-42a4-acf4-fe3ce586d07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical cols: 29\n",
      "Numeric cols: 7\n"
     ]
    }
   ],
   "source": [
    "# 2) Identify feature types\n",
    "#    Heuristic:\n",
    "#    - object columns -> categorical\n",
    "#    - integer columns with low unique count -> categorical codes\n",
    "#    - others -> numeric\n",
    "# -----------------------\n",
    "cat_cols = []\n",
    "num_cols = []\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        cat_cols.append(col)\n",
    "    else:\n",
    "        # treat low-cardinality integers as categorical codes\n",
    "        nunique = X[col].nunique(dropna=True)\n",
    "        if pd.api.types.is_integer_dtype(X[col]) and nunique <= 50:\n",
    "            cat_cols.append(col)\n",
    "        else:\n",
    "            num_cols.append(col)\n",
    "\n",
    "print(\"\\nCategorical cols:\", len(cat_cols))\n",
    "print(\"Numeric cols:\", len(num_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b46b6ec-266b-412d-a593-c12baf4ce97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marital status',\n",
       " 'Application mode',\n",
       " 'Application order',\n",
       " 'Course',\n",
       " 'Daytime/evening attendance\\t',\n",
       " 'Previous qualification',\n",
       " 'Nacionality',\n",
       " \"Mother's qualification\",\n",
       " \"Father's qualification\",\n",
       " \"Mother's occupation\",\n",
       " \"Father's occupation\",\n",
       " 'Displaced',\n",
       " 'Educational special needs',\n",
       " 'Debtor',\n",
       " 'Tuition fees up to date',\n",
       " 'Gender',\n",
       " 'Scholarship holder',\n",
       " 'Age at enrollment',\n",
       " 'International',\n",
       " 'Curricular units 1st sem (credited)',\n",
       " 'Curricular units 1st sem (enrolled)',\n",
       " 'Curricular units 1st sem (evaluations)',\n",
       " 'Curricular units 1st sem (approved)',\n",
       " 'Curricular units 1st sem (without evaluations)',\n",
       " 'Curricular units 2nd sem (credited)',\n",
       " 'Curricular units 2nd sem (enrolled)',\n",
       " 'Curricular units 2nd sem (evaluations)',\n",
       " 'Curricular units 2nd sem (approved)',\n",
       " 'Curricular units 2nd sem (without evaluations)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e66c7ca-7539-49a2-b83b-d89dfc169cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Previous qualification (grade)',\n",
       " 'Admission grade',\n",
       " 'Curricular units 1st sem (grade)',\n",
       " 'Curricular units 2nd sem (grade)',\n",
       " 'Unemployment rate',\n",
       " 'Inflation rate',\n",
       " 'GDP']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87c7b48-cabc-451e-bc0d-c0bd574c294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 3) Preprocessing\n",
    "# -----------------------\n",
    "# For models that use geometry/distance (SVM, KNN, LogisticRegression), scaling helps.\n",
    "# For tree models, scaling not required, but harmless when applied only to numeric.\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_sparse = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))  #default sparse output\n",
    "])\n",
    "\n",
    "categorical_transformer_dense = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "# Sparse preprocessor (good for LogReg/SVM/RF/Tree)\n",
    "preprocess_sparse = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer_sparse, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Dense preprocessor (needed for KNN and GaussianNB; some models don't accept sparse)\n",
    "preprocess_dense = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer_dense, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b8f67e3-3eab-4af7-8b6b-5bce7387b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 4) Train/Test split (stratified because unbalanced)\n",
    "# -----------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 5) Define models (supervised)\n",
    "# -----------------------\n",
    "models = {\n",
    "    \"LogisticRegression\": Pipeline(steps=[\n",
    "        (\"prep\", preprocess_sparse),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            max_iter=2000,\n",
    "            class_weight=\"balanced\",      # handles imbalance\n",
    "            multi_class=\"auto\"\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    \"DecisionTree\": Pipeline(steps=[\n",
    "        (\"prep\", preprocess_sparse),\n",
    "        (\"clf\", DecisionTreeClassifier(\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    \"RandomForest\": Pipeline(steps=[\n",
    "        (\"prep\", preprocess_sparse),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    \"SVM_RBF\": Pipeline(steps=[\n",
    "        (\"prep\", preprocess_sparse),\n",
    "        (\"clf\", SVC(\n",
    "            kernel=\"rbf\",\n",
    "            class_weight=\"balanced\",\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    # KNN needs dense features\n",
    "    \"KNN\": Pipeline(steps=[\n",
    "        (\"prep\", preprocess_dense),\n",
    "        (\"clf\", KNeighborsClassifier(n_neighbors=15))\n",
    "    ]),\n",
    "\n",
    "    # GaussianNB needs dense features\n",
    "    \"GaussianNB\": Pipeline(steps=[\n",
    "        (\"prep\", preprocess_dense),\n",
    "        (\"clf\", GaussianNB())\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b0b4c5-42e8-42f8-9791-8d0c1c8df27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cross-validated model comparison (train set) ===\n",
      "     model  accuracy  balanced_acc  macro_f1  weighted_f1\n",
      "GaussianNB  0.245267      0.383719  0.225497     0.184685\n",
      "\n",
      "Best by macro-F1: GaussianNB\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 6) Cross-validation comparison (train set only)\n",
    "# -----------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_acc\": \"balanced_accuracy\",\n",
    "    \"macro_f1\": \"f1_macro\",\n",
    "    \"weighted_f1\": \"f1_weighted\",\n",
    "}\n",
    "\n",
    "print(\"\\n=== Cross-validated model comparison (train set) ===\")\n",
    "results = []\n",
    "\n",
    "for name, pipe in models.items():\n",
    "        scores = cross_validate(\n",
    "        pipe,\n",
    "        X_train, y_train,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1\n",
    "        )\n",
    "row = {\n",
    "    \"model\": name,\n",
    "    \"accuracy\": np.mean(scores[\"test_accuracy\"]),\n",
    "    \"balanced_acc\": np.mean(scores[\"test_balanced_acc\"]),\n",
    "    \"macro_f1\": np.mean(scores[\"test_macro_f1\"]),\n",
    "    \"weighted_f1\": np.mean(scores[\"test_weighted_f1\"]),\n",
    "}\n",
    "results.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"macro_f1\", ascending=False)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_name = results_df.iloc[0][\"model\"]\n",
    "print(\"\\nBest by macro-F1:\", best_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16ed9cd6-51af-43fa-80da-805894efbc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuning RandomForest (RandomizedSearchCV, macro-F1) ===\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Best CV macro-F1: 0.7154525909912903\n",
      "Best params: {'clf__n_estimators': 500, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 1, 'clf__max_features': 'sqrt', 'clf__max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 7) Hyperparameter tuning (example: RandomForest + SVM)\n",
    "#    We'll tune RF as a strong default.\n",
    "# -----------------------\n",
    "rf_pipe = models[\"RandomForest\"]\n",
    "\n",
    "param_dist = {\n",
    "    \"clf__n_estimators\": [200, 300, 500, 800],\n",
    "    \"clf__max_depth\": [None, 5, 10, 20, 30],\n",
    "    \"clf__min_samples_split\": [2, 5, 10, 20],\n",
    "    \"clf__min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"clf__max_features\": [\"sqrt\", \"log2\", None],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=rf_pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=25,\n",
    "    scoring=\"f1_macro\",           # best for unbalanced multiclass\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\n=== Tuning RandomForest (RandomizedSearchCV, macro-F1) ===\")\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best CV macro-F1:\", search.best_score_)\n",
    "print(\"Best params:\", search.best_params_)\n",
    "\n",
    "best_model = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5976699a-b908-4c29-97c7-3d5099664f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final evaluation on TEST set ===\n",
      "Accuracy: 0.7548022598870057\n",
      "Balanced Accuracy: 0.6983373676132896\n",
      "Macro F1: 0.7007796633806622\n",
      "Weighted F1: 0.7552390149757476\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      " [[195  52  37]\n",
      " [ 27  84  48]\n",
      " [ 14  39 389]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.83      0.69      0.75       284\n",
      "    Enrolled       0.48      0.53      0.50       159\n",
      "    Graduate       0.82      0.88      0.85       442\n",
      "\n",
      "    accuracy                           0.75       885\n",
      "   macro avg       0.71      0.70      0.70       885\n",
      "weighted avg       0.76      0.75      0.76       885\n",
      "\n",
      "\n",
      "=== Optional: SMOTE + RF (CV macro-F1) ===\n",
      "SMOTE RF macro-F1: 0.7107592360114936\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 8) Final evaluation on TEST set\n",
    "# -----------------------\n",
    "print(\"\\n=== Final evaluation on TEST set ===\")\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Weighted F1:\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "\n",
    "print(\"\\nConfusion Matrix (rows=true, cols=pred):\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# -----------------------\n",
    "# 9) OPTIONAL: SMOTE (if imblearn is installed)\n",
    "#    This can help the minority class \"Enrolled\".\n",
    "# -----------------------\n",
    "try:\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    smote_rf = ImbPipeline(steps=[\n",
    "        (\"prep\", preprocess_sparse),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print(\"\\n=== Optional: SMOTE + RF (CV macro-F1) ===\")\n",
    "    scores = cross_validate(smote_rf, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    print(\"SMOTE RF macro-F1:\", np.mean(scores[\"test_macro_f1\"]))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n[Optional SMOTE skipped] imblearn not available or error:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb521383-6953-4f8e-a021-5abdd64912e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
